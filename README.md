# cartpole_dqn
Workshop for DQN

Part 1: DQN
Define the architecture for the deep Q network. For cartpole, the deep Q network should be fully-connected. Do not use batch normalization for non-stationary learning problems.

Part 2: Cart Pole Agent
Initialize cart pole agent.
Have agent select actions using an epsilon-greedy exploration strategy.
Fill out and complete train(), which optimizes the DQN model.
Fill out and complete run_and_visualize() to see how the agent performs on the task.



